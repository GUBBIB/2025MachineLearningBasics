# Conv2D

## 하는 일
- 2D 합성곱 레이어를 만든다.
- 이미지에서 ``특징(feature)`` 을 추출하는 역할을 하며 ``필터(커널)`` 을 이용해 이미지에서 ``중요한 패턴``을 감지한다.<br>
    - 필터를 거쳐서 나온 값이 클수록 특징이 뚜렷하다는 의미이다.

  **※ Conv2D가 특징을 추출하는 방법<br>**
    ``가중치`` 가 들어있는 ``필터(커널)``이 이미지의 **일부 영역**과 ``합성곱 연산`` 을 해서 값을 도출해낸다.
    ``필터(커널)``의 ``가중치``에 따라서 추출하는 **특징** 이 다양하게 나오고 그 ``필터(커널)``의 값은 레이어가 학습을 하면서 **자동** 으로 결정한다.

## 형식
```python
tf.keras.layers.Conv2D(
    filters,               # 출력 채널 수 (= 필터 수)
    kernel_size,           # 필터 크기
    strides=(1, 1),        # 필터 이동 간격
    padding='valid',       # 가장자리 처리 방법
    activation=None,       # 활성화 함수
    use_bias=True,         # 바이어스를 쓸지 말지
    kernel_initializer='glorot_uniform',  # 필터 초기값
    bias_initializer='zeros',             # 바이어스 초기값
    input_shape=None       # 첫 레이어일 때 입력 크기
)
```

- ``filters``: 필터(커널)의 개수이며, 보통 ``32``, ``64``, ``128`` 처럼 필터의 수를 점점 늘린다.
    - 필터의 개수가 2의 배수만큼 늘어나면 연산량도 2배 늘어난다.
    - 2의 승수가 아닌 ``10``, ``20``, ``40`` 을 값으로 줄 수도 있다.
    
    ※ 보통은 filters의 개수가 많을수록 여러가지 필터가 있기 때문에 **다양한 특징**을 추출하지만, **무조건적** 으로 그런것은 아니다.

- ``kernel_size`` : **정방향(3)** 또는 **튜플(3, 3)** 등 ``합성곱``을 할 **필터(커널)** 의 크기를 정한다.
    
- ``strides=(1, 1)`` : 필터(커널)가 움직이는 보폭이다.
    - **필터(커널)** 의 크기가 클수록 **출력 크기가 작아지고** **계산량도 줄어**든다. 하지만 ``MaxPooling2D 연산`` 으로 크기를 줄이기 때문에 보통 기본값인 ``(1, 1)`` 을  사용한다.

- ``padding='valid'`` : 가장자리를 어떻게 처리할지 정한다.
    - ``vaild``: 기본연산이며 가장자리 바깥까지 필터(커널)가 도달하지 못한다.
        - 가장자리 바깥까지 도달하지 못하기 때문에 ``[입력 크기: A, 필터 크기 : n]`` 일 때, 출력 크기가 ``A - (n - 1)`` 로 나온다.
    - ``same`` : 가장자리에 ``0``을 추가해서 **필터(커널)** 가 연산을 가장자리까지 할 수 있게 해준다.<br>
    
    ※ ``valid`` 는 바깥까지 도달하지 못하기 때문에 이미지의 가장자리 특징을 제대로 **추출하지 못하지만** , ``same`` 은 이미지의 **가장자리 특징**까지 **추출할 수 있다**.

- ``activation=None`` : ``활성화 함수``라고 부르며 **필터(커널)** 가 계산해서 만든 값들 중에서 어느 걸 **살릴지** / **버릴지** 를 결정하는 함수 이다.
    - ``ReLU(Rectified Linear Unit)`` : **0보다 작은 값은 모두** ``0``으로 만들고 **0보다 큰 값은 그대로 놔두는** 함수이다. (``x < 0: 0`` , ``x >= 0: x``)
        - 가장 많이 사용되는 함수이다.
        - 중요한 특징만 강조하고, 덜 중요한 특징은 무시하는 함수이다.<br>
        ex) ``[-2, 0, 3] → [0, 0, 3]``

    - ``sigmoid`` : 
    - ``tanh`` : 
    - ``softmax`` : 

    ※ 만약 **활성화 함수** 를 ``none`` 으로 준다면 그저 복잡한 문제는 해결 못하고 **곱셉** + **덧셈** 만 반복하는 ``선형 함수`` 밖에 안 된다. **활성화 함수** 를 선택 해줌으로써 복잡한 문제를 해결 할 수 있는 ``비선형 함수`` 가 된다.


- ``use_bias=True`` :
- ``kernel_initializer='glorot_uniform'`` :
- ``bias_initializer='zeros'`` :
- ``input_shape=None`` :