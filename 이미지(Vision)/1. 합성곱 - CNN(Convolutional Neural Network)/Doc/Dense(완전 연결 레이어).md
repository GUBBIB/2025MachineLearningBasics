# Dense()
## 하는 일
-  ``Conv2D``, ``MaxPooling2D``레이어로 추출한 ``특징``들을 ``Flatten`` 레이어를 이용해서 1차원 벡터로 펼쳐서 **최종적인 판단(분류, 회귀 등)** 이나 **예측**을 내리는 함수이다.

    - 예를들어 ``CNN``에서 **고양이/강아지**를 구분하는 문제에서 ``Dense 레이어`` 가 **특징**들을 보고 **"이건 고양이다!"** 라고 ``결정``을 내리는 부분이다.
    - ``Dense 레이어`` 는 1차원 벡터 형태의 입력만 받을 수 있다.

## 작동 방식
```python
class_name = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']
```

## 형식
```python
tf.keras.layers.Dense(
    units,                 # 출력 노드 수
    activation=None,       # 활성화 함수
    use_bias=True,         # 바이어스 사용 여부
    kernel_initializer='glorot_uniform',  # 가중치 초기값
    bias_initializer='zeros',             # 바이어스 초기값
)
```
*****
- ``units`` : 출력 ``뉴런(값)`` 의 개수를 정한다.
*****
- ``activation=None`` : ``활성화 함수``라고 부르며 **Dense 레이어** 가 계산한 값들 중에서 어느 걸 **살릴지** / **버릴지** 를 결정하는 함수 이다.
    - ``ReLU(Rectified Linear Unit)`` : **0보다 작은 값은 모두** ``0``으로 만들고 **0보다 큰 값은 그대로 놔두는** 함수이다. (``x < 0: 0`` , ``x >= 0: x``)
        - 가장 많이 사용되는 함수이다.
        - 중요한 특징만 강조하고, 덜 중요한 특징은 무시하는 함수이다.<br>
        **ex)** ``[-2, 0, 3] → [0, 0, 3]``

    - ``sigmoid`` : 모든 값을 ``0``과 ``1`` 사이로 **압축** 하는 함수이다.
        - 출력이 확률처럼 보이기 때문에, **이진 분류(yes/no)** 문제에서 자주 사용한다. <br>
        **ex)** `[-2, 0, 2] → [0.12, 0.5, 0.88]`

    - ``tanh`` : 값을 ``-1``과 ``1``사이로 변환한다.
        - ``sigmoid`` 와 비슷하지만 중심이 0이라서 데이터가 **양수/음수**로 나뉘는 경우 더 자연스럽게 작동한다.  
        - 주로 **RNN(순환 신경망)** 등에서 사용된다.  <br>
        **ex)** ``[-2, 0, 2] → [-0.96, 0, 0.96]`` 

    - ``softmax`` : **가장 높은 값을 강조**하고, 전체를 **확률처럼 정규화**한다.  
        - 출력값들의 총합이 1이 되도록 바꿔서, **다중 분류 문제(고양이/강아지/토끼 등)** 에서 사용한다. <br>
        **ex)** ``[2.0, 1.0, 0.1] → [0.65, 0.24, 0.11]``

    ※ 만약 **활성화 함수** 를 ``none`` 으로 준다면 그저 복잡한 문제는 해결 못하고 **곱셉** + **덧셈** 만 반복하는 ``선형 함수`` 밖에 안 된다. **활성화 함수** 를 선택 해줌으로써 복잡한 문제를 해결 할 수 있는 ``비선형 함수`` 가 된다.

*****
- ``use_bias=True`` : ``바이어스``를 사용할지 말지 정하며, 값을 한쪽으로 밀어주는 역할을 한다.<br>
    - **True** : ``바이어스 사용`` <br>
        - 각 필터에 **대응하는 바이어스 값이 존재** 하며 합성곱 연산 결과에 **바이어스를 더해서** 출력값을 조정하단다.
    바이어스를 사용한다면 모델의 표현력이 올라가고, 더욱 유연한 학습이 가능하다.<br>
    
        ※ 바이어스 값은 필터와 마찬가지로 학습 과정에서 ``자동``으로 **조정**되며, **최적의 값**을 찾는다.

    - **False** : ``바이어스 미사용`` <br>
        - 합성곱 연산 결과에 추가적인 조정 없이 그대로 출력한다.
        - 계산이 단순해지며, 표현력이 약해진다.

    - 바이어스 예시 사진
        - ``빨간 실선 = 바이어스가 3인 경우``, ``파란색 점선 = 바이어스가 없는 경우``
    
    <img src="https://github.com/user-attachments/assets/46fa0f31-8a1c-4a1e-9217-6e24b35a8c4e" width="500px" height="500px">


    ※ 위의 그래프처럼 출력값을 각 필터마다 ``위/아래`` 로 밀어줌으로써 **단순한 선형 패턴** 에서 **비선형적인 패턴** 으로 학습을 할 수 있게 해준다.<br>

*****
- ``kernel_initializer='glorot_uniform'`` : ``가중치``의 **초기값**을 정한다.
    - ``glorot_uniform``이 기본값으로 **Xavier 초기화** 라고부르며, **균등분포** 기반으로 적적히 분산된 값으로 초기화한다.
    
    ※ 이외에 ``정규분포 기반``, ``균등분포 기반`` 등 여러가지가 있지만 특수한 상황이 아닌경우는 전부 다 ``glorot_uniform``을 사용한다.

*****
- ``bias_initializer='zeros'`` : 바이어스의 초기값을 정한다.
    - ``zeros``는 모든 바이어스의 초기값을 0으로 초기화시킨다.
    
    ※ ``zeros`` 말고도 ``ones``, ``random_normal`` 등 여러가지가 있지만 실험적 설정 또는 특수한 상황이 아닌경우는 전부 다 ``zeros``를 사용한다.
*****

