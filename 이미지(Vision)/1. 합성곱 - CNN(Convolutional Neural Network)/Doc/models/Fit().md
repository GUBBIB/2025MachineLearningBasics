# Fit()
## 하는 일
- 모델에 데이터를 넣어서 합습시키는 함수이다.

## 용어 설명
| 용어   | 의미 |
|--------|------|
| **Step**  | 배치 하나를 모델이 처리하는 단위 (`batch_size` 기준) |
| **Batch** | 한 번에 모델에 들어가는 데이터 묶음 (`batch_size`만큼) |
| **Epoch** | 전체 훈련 데이터를 한 바퀴 다 도는 것 |

## 형식
```python
model.fit(
    x=None,
    y=None,
    batch_size=None,
    epochs=1,
    verbose=1,
    callbacks=None,
    validation_split=0.0,
    validation_data=None,
    shuffle=True,
    class_weight=None,
    sample_weight=None,
    initial_epoch=0,
    steps_per_epoch=None,
    validation_steps=None,
    validation_batch_size=None,
    validation_freq=1,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False
)
```
*****
- ``x=None`` : ``입력 데이터``를 설정한다.
    - 이 챕터에서는 로드한 데이터인 ``train_images``를 넣는다.

*****
- ``y=None`` : ``입력 데이터``에 대한 ``정답 데이터``를 설정한다.
    - 이 챕터에서는 로드한 데이터인 ``train_labels``를 넣는다.

*****
- ``batch_size=None`` :  한 번의 학습 스텝(step)에서 사용할 데이터 묶음의 크기를 설정한다.
    - **기본값**은 ``None``이지만 TensorFlow가 내부적으로 ``32``를 값으로 준다.

*****
- ``epochs=1`` : ``전체 훈련 데이터``를 **몇 번 반복**해서 학습할지 설정한다.
    - ``epochs`` 가 너무 작으면 **학습이 부족**하고, 너무 크면 **과적합(overfitting)** 이 발생할 수 있다
*****
- ``verbose=1`` : 훈련 중 로그(log) 출력 형태를 설정한다.
    - ``0`` : 아무것도 출력하지 않는다.
    - ``1`` : ``Epochs`` 마다 한 줄씩 출력한다.
        ```python
        Epoch 1/3
        1563/1563 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.6437 - accuracy: 0.7729
        Epoch 2/3
        1563/1563 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.5001 - accuracy: 0.8200
        ...
        ```

    - ``2`` : 진행 막대 없이 ``Epochs`` 마다 한 줄씩 출력한다.
        ```python
        Epoch 1/3 - loss: 0.6437 - accuracy: 0.7729
        Epoch 2/3 - loss: 0.5001 - accuracy: 0.8200
        Epoch 3/3 - loss: 0.4002 - accuracy: 0.8600
        ...
        ```

*****
- ``callbacks=None`` : 훈련도중 **특정 시점마다 자동**으로 실행되는 **함수의 집합**을 설정한다.

    |콜백 이름|설명|
    |---------------------|-------------------------------------------|
    | `EarlyStopping`| 성능 향상이 없을 경우 **자동으로 훈련 중단** |
    | `ModelCheckpoint`| **모델을 저장** (파일로)|
    | `ReduceLROnPlateau`| 성능이 정체되면 **학습률 자동 조정**|
    | `TensorBoard`| 훈련 로그를 **시각화**|
    | `CSVLogger`| 로그를 **CSV 파일로 저장**|


*****
- ``validation_split=0.0`` : ``훈련 데이터``인 ``x``, ``y``에서 **일정 비율만큼** 떼어내어 ``검증 데이터``로 사용할지 설정한다.
    - 일반적으로는 ``validation_data``를 따로 설정하지만,
**검증용 데이터가 따로 없을 때** 또는
**test 데이터를 최종 평가용으로만 쓸 때** 사용한다.

*****
- ``validation_data=None`` : 모델 훈련 중 검**증에 사용할 데이터셋**을 직접 설정한다.
    - ``(val_x, val_y)`` 또는 ``tf.data.Dataset`` 형태여야만 한다.
    - ``val_x``는 **입력 데이터**, ``val_y``는 **정답(labels) 데이터**이다.
    - ``validation_data``를 설정하면 ``validation_split``은 **무시된다**.

*****
- ``shuffle=True`` : ``훈련 데이터``를 ``Epochs`` 마다 섞을지 설정한다
    - ``True``면 각 ``Epochs``가 시작되기 전에 ``훈련 데이터``를 **섞는다**.
        - 모델이 **특정 순서에 과적합**되는 것을 방지할 수 있다.
    - ``False``면 ``훈련 데이터``를 **섞지 않고** 입력 순서대로 학습한다.
        - 시계열 데이터처럼 **순서가 중요한 데이터**일 때 사용한다.

*****
- ``class_weight=None`` : 각 ``클래스(정답 라벨)``에 대해 **가중치**를 다르게 줄 수 있다.
    - 불균형 데이터셋에서 유용하다
    - 예를 들어, 클래스 0이 ``900``개, 클래스 1이 ``100``개인 데이터셋이라면 ``기본 설정(class_weight=None)``일 경우, 모델은 클래스 0만 예측해도 ``90%`` **정확도**를 달성할 수 있기 때문에 클래스 1을 **무시**할 가능성이 높다.
    - 이럴 때, ``class_weight``로 클래스 1에 더 높은 가중치를 주면 모델이 클래스 1을 더 중요하게 학습하도록 유도할 수 있다.<br>

    ```python
    class_weight = {
        0: 1.0,   # 클래스 0은 기본
        1: 9.0    # 클래스 1은 9배 더 중요하게
    }
    ```

*****
- ``sample_weight=None`` : 훈련 데이터의 **각 샘플(데이터 한개)** 마다 **개별적인 가중치**를 줄 수 있다.
    - ``class_weight``가 클래스 단위로 **가중치**를 주는 것이라면, ``sample_weight``는 **데이터 하나하나마다 세밀하게 가중치**를 줄 수 있다.<br>

    ```python
    # 예시: 첫 번째 샘플의 중요도를 2배로, 나머지는 1배로
    sample_weight = [2.0, 1.0, 1.0, 1.0, ...]
    ```

*****
- ``initial_epoch=0`` : 모델 훈련을 **몇 번째 ``epoch``부터 시작할지** 설정한다.
    - 훈련을 중간에 끊었다가 **이어하기(재학습)** 할 때 유용하다.

*****
- ``steps_per_epoch=None`` : 한 ``epoch``동안 훈련에 사용할 스텝 수를 정한다.
    - 기본값은 ``None``이며, 이 경우에는 전체 데이터를 ``batch_size``로 **나눈 횟수만큼 자동으로 설정**된다.
    
        **!** 데이터 ``20,000``개, ``batch_size`` = ``100``이면 → ``steps_per_epoch`` = ``200``

*****
- ``validation_steps=None`` : ``검증 데이터셋(validation_data)``을 사용할 때, 몇 번의 ``step``으로 검증을 수행할지 설정한다.
    - 직접 값을 정할 수 있지만 ``기본값(None)``으로 둘 경우 **자동**으로 계산한다.

*****
- ``validation_batch_size=None`` : ``검증 데이터``를 평가할 때 사용할 ``배치 크기(batch_size)``를 설정한다.
    - 기본값은 ``None``이며, 이 경우 훈련에 사용된 ``batch_size``와 동일하게 설정된다.
    - 훈련은 **작은 배치**로 하고, 검증은 **큰 배치**로 **빠르게 처리하고 싶을 때** 유용하다.

*****
- ``validation_freq=1`` : 몇 번째 ``epochs``마다 **검증(validation)** 을 수행할지 정의한다.

    ```python
    # 예시
    model.fit(x, y, validation_data=(val_x, val_y), validation_freq=3)
    ```
    - 이 경우 ``3``, ``6``, ``9``... 번째 에포크에서만 ``검증 데이터``로 평가를 진행함.

*****
- ``max_queue_size=10`` : **데이터 생성기(generator 또는 tf.data)** 를 사용할 때, 데이터를 미리 불러와 저장해둘 수 있는 최대 큐(queue)의 크기를 설정한다.
    - **기본값**은 ``10``이며, 이는 **최대 10개의 배치(batch) 를 미리 준비해둘 수 있다**는 뜻이다.

*****
- ``workers=1`` :  데이터를 **병렬로 로드할 때** 사용할 ``프로세스 수``를 설정한다.

    - 주로 ``fit()``에서 **데이터 생성기(generator)** 나 **tf.data.Dataset**을 사용할 때 효과가 있다.
    - **기본값**은 ``1``이며, 이는 하나의 ``워커(worker, 즉 프로세스)`` 만 데이터를 로드한다는 뜻이다.
    - 만약 값이 ``4``라면, **4개의 프로세스**가 **동시**에 데이터를 불러오기 때문에 **데이터 준비 속도가 빨라지고 전체 학습 속도가 향상**될 수 있다.
    - 단, 워커 수가 많을수록 메모리 사용량이 증가한다.

*****
- ``use_multiprocessing=False`` : 데이터를 로딩할 때 **멀티프로세싱을 사용할지 여부**를 설정한다.
    - ``workers`` 값이 ``1``보다 **클 때만** 의미가 있다.
    - ``True``로 설정 시, ``프로세스 기반 병렬 처리``를 사용한다.
    - ``False``로 설정 시, **스레드 기반 처리**를 사용한다.

*****